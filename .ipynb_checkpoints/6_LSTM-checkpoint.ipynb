{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "batch_size = 128\n",
    "nb_epoch = 50\n",
    "\n",
    "# Parameters for MNIST dataset\n",
    "img_rows, img_cols = 28, 28\n",
    "nb_classes = 10\n",
    "\n",
    "# Parameters for LSTM network\n",
    "nb_lstm_outputs = 30\n",
    "nb_time_steps = img_rows\n",
    "dim_input_vector = img_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train original shape: (60000, 28, 28)\n",
      "X_train shape: (60000, 28, 28)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print('X_train original shape:', X_train.shape)\n",
    "input_shape = (nb_time_steps, dim_input_vector)\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 30)                7080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 7,390\n",
      "Trainable params: 7,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/miniconda3/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_initializer=\"normal\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(nb_lstm_outputs, input_shape=input_shape))\n",
    "model.add(Dense(nb_classes, activation='softmax', init='normal'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/miniconda3/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 16s 269us/step - loss: 1.3243 - acc: 0.5799\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 0.5769 - acc: 0.8217\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 16s 265us/step - loss: 0.3721 - acc: 0.8906\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 14s 240us/step - loss: 0.2734 - acc: 0.9204\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.2147 - acc: 0.9374\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 0.1748 - acc: 0.9499\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 0.1514 - acc: 0.9563\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: 0.1335 - acc: 0.9608\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 18s 292us/step - loss: 0.1206 - acc: 0.9642\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.1101 - acc: 0.9677\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 21s 346us/step - loss: 0.1027 - acc: 0.9701\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 0.0962 - acc: 0.9716\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 0.0899 - acc: 0.9730\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 15s 245us/step - loss: 0.0842 - acc: 0.9748\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 15s 251us/step - loss: 0.0804 - acc: 0.9763\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 23s 378us/step - loss: 0.0761 - acc: 0.9774\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 20s 326us/step - loss: 0.0724 - acc: 0.9787\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 0.0693 - acc: 0.9791\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.0663 - acc: 0.9801\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 16s 264us/step - loss: 0.0638 - acc: 0.9811\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 19s 309us/step - loss: 0.0601 - acc: 0.9819\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 16s 269us/step - loss: 0.0572 - acc: 0.98240s - loss: 0.0575 - a\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 16s 270us/step - loss: 0.0557 - acc: 0.9831\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 0.0536 - acc: 0.9835\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 16s 269us/step - loss: 0.0505 - acc: 0.98411s - loss: 0.0\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.0499 - acc: 0.9844\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 17s 287us/step - loss: 0.0477 - acc: 0.9855\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 18s 303us/step - loss: 0.0463 - acc: 0.9855\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.0446 - acc: 0.9862\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.0430 - acc: 0.9866\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 18s 303us/step - loss: 0.0421 - acc: 0.9872\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 19s 310us/step - loss: 0.0412 - acc: 0.98752\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 20s 327us/step - loss: 0.0387 - acc: 0.9879\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 18s 304us/step - loss: 0.0381 - acc: 0.9880\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.0369 - acc: 0.9882\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0354 - acc: 0.9889\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 21s 354us/step - loss: 0.0350 - acc: 0.9893\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 18s 306us/step - loss: 0.0343 - acc: 0.9891\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 19s 312us/step - loss: 0.0331 - acc: 0.9896\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.0318 - acc: 0.9899\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 18s 303us/step - loss: 0.0312 - acc: 0.9902\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 18s 308us/step - loss: 0.0311 - acc: 0.9901\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 19s 319us/step - loss: 0.0296 - acc: 0.9907\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 19s 315us/step - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 19s 319us/step - loss: 0.0279 - acc: 0.99153s - loss: 0.02 - ETA: 2s - loss - ETA: 0s - loss: 0.0278\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 19s 316us/step - loss: 0.0266 - acc: 0.99180s - loss: 0.0266 - acc:\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 21s 350us/step - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 19s 320us/step - loss: 0.0258 - acc: 0.9922\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 19s 319us/step - loss: 0.0249 - acc: 0.9921\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history = model.fit(X_train, Y_train, nb_epoch=nb_epoch, batch_size=batch_size, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 97us/step\n",
      "Summary: Loss over the test dataset: 0.08, Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "evaluation = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=1)\n",
    "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
